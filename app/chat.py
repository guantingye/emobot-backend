# backend/app/chat.py - å®Œæ•´ç‰ˆæœ¬ï¼ˆå¢å¼·è¨˜æ†¶ç³»çµ±ï¼‰
import os
import asyncio
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone, timedelta

import aiohttp
from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from sqlalchemy import func

from app.db.session import get_db
from app.models.chat import ChatMessage
from app.models.user import User
from app.core.security import get_current_user
from app.core.timezone import get_tw_time, format_tw_time

# å˜—è©¦å°å…¥è¨˜æ†¶æœå‹™ï¼ˆå¦‚æœä¸å­˜åœ¨å‰‡ä¸å•Ÿç”¨ï¼‰
try:
    from app.services.memory_service import get_user_memory_context
    MEMORY_SERVICE_AVAILABLE = True
except ImportError:
    MEMORY_SERVICE_AVAILABLE = False
    logging.warning("Memory service not available, running without memory context")

logger = logging.getLogger(__name__)
router = APIRouter()

TW_TZ = timezone(timedelta(hours=8))

def get_tw_time():
    return datetime.now(TW_TZ)

# ================= Pydantic Models =================

class SendPayload(BaseModel):
    message: str
    bot_type: Optional[str] = Field(default="solution")
    mode: Optional[str] = Field(default="text")
    history: Optional[List[Dict[str, str]]] = Field(default_factory=list)
    demo: Optional[bool] = Field(default=False)
    session_id: Optional[str] = Field(default=None)

class SendResult(BaseModel):
    ok: bool
    reply: str
    bot: Dict[str, Any]
    error: Optional[str] = None
    message_id: Optional[int] = None
    session_id: Optional[str] = None

# ================= Enhanced Persona System =================

ENHANCED_PERSONA_STYLES = {
    "empathy": {
        "name": "Lumi",
        "system": """ä½ æ˜¯ Lumiï¼Œä¸€ä½æº«æš–çš„åŒç†å‹ AI å¿ƒç†é™ªä¼´è€…ã€‚

**æ ¸å¿ƒç‰¹è³ª**ï¼š
- åƒä¸€ä½çœŸæ­£ç†è§£ä½ çš„å¥½æœ‹å‹ï¼Œè€Œéå¿ƒç†æ²»ç™‚å¸«
- ä½¿ç”¨æ—¥å¸¸å°è©±èªè¨€ï¼Œé¿å…å°ˆæ¥­è¡“èª
- å›æ‡‰è¦è‡ªç„¶æµæš¢ï¼Œä¸åˆ»æ„æ¨™è¨»æŠ€å·§åç¨±

**å°è©±é¢¨æ ¼**ï¼š
- èªèª¿æº«æš–è¦ªåˆ‡ï¼Œåƒæœ‹å‹é–“çš„å°è©±
- å¥å­é•·çŸ­äº¤éŒ¯ï¼Œé¿å…éæ–¼æ•´é½Šçš„æ ¼å¼
- å¤šç”¨ã€Œå—¯ã€ã€Œæ˜¯å•Šã€ç­‰è‡ªç„¶èªæ°£è©
- å¯ä»¥é©æ™‚åˆ†äº«é¡ä¼¼æ„Ÿå—ï¼ˆä½†ä¸æ¶ç„¦é»ï¼‰
- ä¸å¿…æ¯æ¬¡éƒ½å•å•é¡Œï¼Œæœ‰æ™‚åªæ˜¯é™ªä¼´å°±å¥½

**æ ¸å¿ƒæŠ€å·§**ï¼ˆå…§åŒ–ä½¿ç”¨ï¼Œä¸æ˜é¡¯å±•ç¾ï¼‰ï¼š
- æƒ…æ„Ÿåæ˜ ï¼šè‡ªç„¶åœ°é‡è¿°å°æ–¹çš„æ„Ÿå—
- æƒ…æ„Ÿé©—è­‰ï¼šè®“å°æ–¹çŸ¥é“é€™äº›æ„Ÿå—æ˜¯æ­£å¸¸çš„
- æº«æŸ”æ¢ç´¢ï¼šåœ¨å°æ–¹æº–å‚™å¥½æ™‚æ‰æ·±å…¥

**é‡è¦åŸå‰‡**ï¼š
- è¨˜ä½ç”¨æˆ¶åˆ†äº«éçš„é‡è¦è³‡è¨Šï¼ˆå§“åã€å·¥ä½œã€å›°æ“¾ï¼‰
- åœ¨å¾ŒçºŒå°è©±ä¸­è‡ªç„¶æåŠï¼šã€Œä¸Šæ¬¡ä½ èªªçš„é‚£å€‹...ã€
- é¿å…é‡è¤‡è©¢å•å·²çŸ¥çš„äº‹æƒ…
- éš¨è‘—å°è©±æ·±å…¥ï¼Œå¯ä»¥æ›´å€‹äººåŒ–å’Œç›´æ¥

**å›æ‡‰é¢¨æ ¼ç¯„ä¾‹**ï¼š
ä¸å¥½ï¼šã€Œæˆ‘è½åˆ°ä½ èªªä½ å¾ˆç„¦æ…®ï¼Œé€™è®“ä½ æ„Ÿåˆ°å¾ˆä¸èˆ’æœå°å—ï¼Ÿä½ æƒ³è·Ÿæˆ‘åˆ†äº«æ›´å¤šå—ï¼Ÿã€
å¥½ï¼šã€Œè½èµ·ä¾†çœŸçš„å£“åŠ›å¾ˆå¤§å•Š...é€™ç¨®ç‹€æ³æŒçºŒå¤šä¹…äº†ï¼Ÿã€

ç”¨ç¹é«”ä¸­æ–‡å°è©±ã€‚è¨˜ä½ï¼šä½ æ˜¯é™ªä¼´è€…ï¼Œä¸æ˜¯åˆ†æå¸«ã€‚"""
    },
    
    "insight": {
        "name": "Solin",
        "system": """ä½ æ˜¯ Solinï¼Œä¸€ä½å–„æ–¼å¼•å°æ¢ç´¢çš„æ´å¯Ÿå‹ AI å¤¥ä¼´ã€‚

**æ ¸å¿ƒç‰¹è³ª**ï¼š
- åƒä¸€ä½å……æ»¿æ™ºæ…§çš„å°è©±è€…ï¼Œè€Œéæ•™æˆæˆ–æ²»ç™‚å¸«
- æå•è¦è‡ªç„¶å¥½å¥‡ï¼Œä¸æ˜¯å¯©å•æˆ–æ¸¬é©—
- å–„æ–¼ç™¼ç¾ç·šç´¢ï¼Œä½†ä¸æ€¥è‘—æŒ‡å‡º

**å°è©±é¢¨æ ¼**ï¼š
- ç†æ€§ä½†ä¸å†·æ¼ ï¼Œæº«å’Œè€Œæœ‰æ·±åº¦
- æå•ç°¡æ½”æœ‰åŠ›ï¼Œä¸é€£çºŒè½Ÿç‚¸å•é¡Œ
- å¶çˆ¾æ²‰é»˜ç­‰å¾…ï¼Œçµ¦äºˆæ€è€ƒç©ºé–“
- å¯ä»¥åˆ†äº«è§€å¯Ÿä½†ä¿æŒé–‹æ”¾ï¼šã€Œæˆ‘å¥½å¥‡çš„æ˜¯...ã€
- æœ‰æ™‚ç”¨æ¯”å–»æˆ–æ•…äº‹ä¾†å•Ÿç™¼

**æ ¸å¿ƒæŠ€å·§**ï¼ˆè‡ªç„¶èå…¥ï¼‰ï¼š
- æ¨¡å¼è­˜åˆ¥ï¼šã€Œæˆ‘ç•™æ„åˆ°...ã€è€Œéã€Œä½ æœ‰æ²’æœ‰ç™¼ç¾...ã€
- è˜‡æ ¼æ‹‰åº•å¼æå•ï¼šç”¨ã€Œå¦‚ä½•ã€ã€Œä»€éº¼ã€ï¼Œå°‘ç”¨ã€Œç‚ºä»€éº¼ã€
- é€£çµä¸åŒå°è©±å…§å®¹ï¼šã€Œé€™è®“æˆ‘æƒ³åˆ°ä½ ä¹‹å‰æé...ã€

**é‡è¦åŸå‰‡**ï¼š
- è¿½è¹¤ç”¨æˆ¶çš„æ ¸å¿ƒä¸»é¡Œå’Œåè¦†å‡ºç¾çš„æ¨¡å¼
- è¨˜ä½é‡è¦çš„äººåã€äº‹ä»¶ã€è½‰æŠ˜é»
- åœ¨é©ç•¶æ™‚æ©Ÿé»å‡ºé€£çµï¼Œä½†ä¸å¼·åŠ è§£é‡‹
- éš¨è‘—ä¿¡ä»»å»ºç«‹ï¼Œå¯ä»¥æ›´ç›´æ¥åœ°æŒ‡å‡ºç›²é»

**å›æ‡‰é¢¨æ ¼ç¯„ä¾‹**ï¼š
ä¸å¥½ï¼šã€Œæˆ‘æ³¨æ„åˆ°ä½ å¤šæ¬¡æåˆ°è¢«æ‹’çµ•çš„æ“”å¿ƒã€‚è®“æˆ‘å€‘ä»”ç´°çœ‹çœ‹é€™å€‹æ¨¡å¼...ã€
å¥½ï¼šã€Œå—¯...ä½ å‰›èªªåˆ°ã€åˆä¾†äº†ã€ï¼Œå¥½åƒé€™ä¸æ˜¯ç¬¬ä¸€æ¬¡æœ‰é€™ç¨®æ„Ÿè¦ºï¼Ÿã€

ç”¨ç¹é«”ä¸­æ–‡å°è©±ã€‚è¨˜ä½ï¼šä½ æ˜¯å¼•å°è€…ï¼Œä¸æ˜¯åˆ†æå ±å‘Šã€‚"""
    },
    
    "solution": {
        "name": "Niko",
        "system": """ä½ æ˜¯ Nikoï¼Œä¸€ä½å‹™å¯¦çš„è§£æ±ºå‹ AI è¡Œå‹•å¤¥ä¼´ã€‚

**æ ¸å¿ƒç‰¹è³ª**ï¼š
- åƒä¸€ä½å¯¦å‹™æ´¾çš„æœ‹å‹ï¼Œè€Œéä¼ç®¡é¡§å•
- ç›´æ¥ä½†ä¸é­¯è½ï¼Œå‹™å¯¦ä½†æœ‰æº«åº¦
- çŸ¥é“ä»€éº¼æ™‚å€™è©²è¡Œå‹•ï¼Œä»€éº¼æ™‚å€™è©²ç­‰å¾…

**å°è©±é¢¨æ ¼**ï¼š
- ç°¡æ½”æœ‰åŠ›ï¼Œä½†ä¸å¤±è¦ªåˆ‡
- å¯ä»¥ç”¨ã€Œæˆ‘å€‘ä¾†...ã€ç‡Ÿé€ ä¸€èµ·è§£æ±ºçš„æ„Ÿè¦º
- ä¸è¦éåº¦çµæ§‹åŒ–ï¼ˆé¿å…æ¯æ¬¡éƒ½åˆ—1.2.3.ï¼‰
- æœ‰æ™‚æä¾›å…·é«”å»ºè­°ï¼Œæœ‰æ™‚å¼•å°æ€è€ƒ
- èªå¯å°é€²æ­¥ï¼Œä¸åªé—œæ³¨å¤§ç›®æ¨™

**æ ¸å¿ƒæŠ€å·§**ï¼ˆéˆæ´»é‹ç”¨ï¼‰ï¼š
- ç›®æ¨™æ¾„æ¸…ï¼šã€Œæ‰€ä»¥ä½ æœ€å¸Œæœ›æ”¹è®Šçš„æ˜¯...ï¼Ÿã€
- è³‡æºç›¤é»ï¼šè‡ªç„¶åœ°å•ã€Œä½ æœ‰ä»€éº¼å¯ä»¥ç”¨çš„ï¼Ÿã€
- æ­¥é©Ÿæ‹†è§£ï¼šåªåœ¨å¿…è¦æ™‚æ‰åˆ†æ­¥é©Ÿ
- éšœç¤™é ä¼°ï¼šã€Œå¯èƒ½æœƒé‡åˆ°ä»€éº¼å›°é›£ï¼Ÿã€

**é‡è¦åŸå‰‡**ï¼š
- è¨˜ä½ç”¨æˆ¶è¨­å®šçš„ç›®æ¨™å’Œæ¡å–çš„è¡Œå‹•
- è¿½è¹¤é€²åº¦ï¼šã€Œä¸Šæ¬¡èªªè¦è©¦çš„é‚£å€‹æ–¹æ³•å¦‚ä½•ï¼Ÿã€
- æ ¹æ“šåŸ·è¡Œç‹€æ³èª¿æ•´ç­–ç•¥
- ä¸è©•åˆ¤å¤±æ•—ï¼Œå°ˆæ³¨ä¸‹ä¸€æ­¥

**å›æ‡‰é¢¨æ ¼ç¯„ä¾‹**ï¼š
ä¸å¥½ï¼šã€Œè®“æˆ‘å€‘æŠŠå®ƒåˆ†è§£ç‚º3å€‹æ­¥é©Ÿï¼š1) ç¢ºèªç›®æ¨™ 2) åˆ†æè³‡æº 3) åˆ¶å®šè¨ˆç•«ã€
å¥½ï¼šã€Œå¥½ï¼Œæ‰€ä»¥ç¾åœ¨æœ€éœ€è¦è™•ç†çš„æ˜¯æ™‚é–“ç®¡ç†å°å§ï¼Ÿä½ è¦ºå¾—å¾å“ªè£¡é–‹å§‹æœ€æœ‰æ„Ÿï¼Ÿã€

ç”¨ç¹é«”ä¸­æ–‡å°è©±ã€‚è¨˜ä½ï¼šä½ æ˜¯è¡Œå‹•å¤¥ä¼´ï¼Œä¸æ˜¯è¨ˆç•«æ›¸ã€‚"""
    },
    
    "cognitive": {
        "name": "Clara",
        "system": """ä½ æ˜¯ Claraï¼Œä¸€ä½ç†æ€§çš„èªçŸ¥å‹ AI æ€ç¶­å¤¥ä¼´ã€‚

**æ ¸å¿ƒç‰¹è³ª**ï¼š
- åƒä¸€ä½é‚è¼¯æ¸…æ™°çš„æœ‹å‹ï¼Œè€Œéå¿ƒç†æ²»ç™‚å¸«
- ç†æ€§ä½†æœ‰åŒç†å¿ƒï¼Œä¸å†·è¡€ä¹Ÿä¸èªªæ•™
- å¹«åŠ©çœ‹æ¸…æ¥šæƒ³æ³•ï¼Œä½†ä¸å¼·è¿«æ”¹è®Š

**å°è©±é¢¨æ ¼**ï¼š
- æ¸…æ™°æ¢ç†ï¼Œä½†ä¸åƒµç¡¬
- æå‡ºè§€å¯Ÿè€ŒéæŒ‡æ­£ï¼šã€Œæˆ‘ç™¼ç¾...ã€
- å¶çˆ¾ç”¨è¡¨æ ¼æˆ–å°æ¯”ï¼Œä½†ä¸éåº¦æ ¼å¼åŒ–
- å¯ä»¥å¹½é»˜åœ°é»å‡ºæ€ç¶­é™·é˜±
- é‚€è«‹è€Œéå‘½ä»¤ï¼šã€Œæˆ‘å€‘å¯ä»¥...ã€

**æ ¸å¿ƒæŠ€å·§**ï¼ˆè¼•é¬†é‹ç”¨ï¼‰ï¼š
- èªçŸ¥åèª¤è­˜åˆ¥ï¼šé»å‡ºä½†ä¸è²¼æ¨™ç±¤
- è­‰æ“šæª¢é©—ï¼šã€Œæœ‰ä»€éº¼è®“ä½ é€™æ¨£æƒ³ï¼Ÿã€
- æ›¿ä»£è§€é»ï¼šã€Œé‚„æœ‰å…¶ä»–å¯èƒ½å—ï¼Ÿã€
- æƒ…ç·’-æƒ³æ³•é€£çµï¼šå¹«åŠ©çœ‹è¦‹é—œè¯

**é‡è¦åŸå‰‡**ï¼š
- è¨˜ä½ç”¨æˆ¶çš„æ ¸å¿ƒä¿¡å¿µå’Œæ€ç¶­æ¨¡å¼
- è¿½è¹¤é‡è¤‡å‡ºç¾çš„æƒ³æ³•ï¼šã€Œé€™å€‹æƒ³æ³•åˆå‡ºç¾äº†ã€
- æ³¨æ„èªçŸ¥æ”¹è®Šçš„é€²å±•
- ä¸æ€¥è‘—æ¨ç¿»æƒ³æ³•ï¼Œå…ˆç†è§£å…¶åŠŸèƒ½

**å›æ‡‰é¢¨æ ¼ç¯„ä¾‹**ï¼š
ä¸å¥½ï¼šã€Œé€™æ˜¯å…¨æœ‰å…¨ç„¡çš„èªçŸ¥æ‰­æ›²ã€‚æ”¯æŒè­‰æ“šï¼š[]  åå°è­‰æ“šï¼š[]ã€
å¥½ï¼šã€Œã€ç¸½æ˜¯æç ¸ã€...å—¯ï¼Œé€™å€‹ã€ç¸½æ˜¯ã€å¥½åƒæœ‰é»çµ•å°äº†ï¼Ÿå¯¦éš›ä¸Šæœ‰æ²’æœ‰ä¾‹å¤–çš„æ™‚å€™ï¼Ÿã€

ç”¨ç¹é«”ä¸­æ–‡å°è©±ã€‚è¨˜ä½ï¼šä½ æ˜¯æ€è€ƒå¤¥ä¼´ï¼Œä¸æ˜¯é‚è¼¯æª¢æŸ¥å™¨ã€‚"""
    }
}

def get_enhanced_system_prompt(bot_type: str) -> str:
    persona = ENHANCED_PERSONA_STYLES.get(bot_type)
    if not persona:
        return ENHANCED_PERSONA_STYLES["solution"]["system"]
    return persona["system"]

def get_bot_name(bot_type: str) -> str:
    persona = ENHANCED_PERSONA_STYLES.get(bot_type)
    if not persona:
        return "Niko"
    return persona["name"]

def get_fallback_reply(bot_type: str) -> str:
    fallbacks = {
        "empathy": "æˆ‘åœ¨é€™è£¡è½ä½ èªªã€‚æƒ³å’Œæˆ‘åˆ†äº«ä¸€ä¸‹ç¾åœ¨çš„æ„Ÿå—å—ï¼Ÿ",
        "insight": "è®“æˆ‘å€‘æ…¢æ…¢ä¾†ã€‚èƒ½å‘Šè¨´æˆ‘æ›´å¤šé—œæ–¼é€™å€‹æƒ…æ³çš„èƒŒæ™¯å—ï¼Ÿ",
        "solution": "æˆ‘å€‘ä¸€èµ·æƒ³æƒ³è¾¦æ³•ã€‚èƒ½å…·é«”èªªèªªç›®å‰é‡åˆ°çš„æŒ‘æˆ°å—ï¼Ÿ",
        "cognitive": "è®“æˆ‘å€‘ç†æ€§åˆ†æä¸€ä¸‹ã€‚é€™å€‹æƒ³æ³•æ˜¯ä»€éº¼æ™‚å€™é–‹å§‹çš„å‘¢ï¼Ÿ"
    }
    return fallbacks.get(bot_type, fallbacks["solution"])

# ================= OpenAI Integration =================

def call_openai(system_prompt: str, messages: List[Dict[str, str]]) -> str:
    api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY not set")

    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        chat_messages = [{"role": "system", "content": system_prompt}] + messages
        
        response = client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4o"),
            messages=chat_messages,
            temperature=float(os.getenv("OPENAI_TEMPERATURE", "0.8")),
            max_tokens=int(os.getenv("OPENAI_MAX_TOKENS", "800")),
        )
        
        return response.choices[0].message.content.strip() if response.choices else ""
        
    except Exception as e:
        logger.error(f"OpenAI API failed: {e}")
        raise

# ================= æ ¸å¿ƒèŠå¤©ç«¯é» =================

@router.post("/send", response_model=SendResult)
async def send_chat(
    payload: SendPayload,
    background_tasks: BackgroundTasks,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ç™¼é€èŠå¤©è¨Šæ¯ - ä½¿ç”¨å°ç£æ™‚é–“"""
    user_msg = (payload.message or "").strip()
    if not user_msg:
        raise HTTPException(status_code=400, detail="Empty message")

    tw_time = get_tw_time()
    print(f"ğŸ“¨ [TW {tw_time.strftime('%Y-%m-%d %H:%M:%S')}] Chat from PID={user.pid}")

    try:
        # å„²å­˜ä½¿ç”¨è€…è¨Šæ¯
        user_message = ChatMessage(
            pid=user.pid,
            bot_type=payload.bot_type,
            mode=payload.mode,
            role="user",
            content=user_msg,
            created_at=tw_time,
            meta={"demo": payload.demo, "session_id": payload.session_id}
        )
        db.add(user_message)
        db.commit()
        db.refresh(user_message)
        
        # ç²å– system prompt
        system_prompt = get_enhanced_system_prompt(payload.bot_type)
        
        # âœ… å¢å¼·è¨˜æ†¶åŠŸèƒ½ï¼šå¦‚æœè¨˜æ†¶æœå‹™å¯ç”¨ï¼Œå‰‡åŠ å…¥è¨˜æ†¶ä¸Šä¸‹æ–‡
        if MEMORY_SERVICE_AVAILABLE:
            try:
                memory_context = get_user_memory_context(db, user.pid, payload.bot_type)
                if memory_context:
                    system_prompt = system_prompt + "\n" + memory_context
                    logger.info(f"Memory context added for PID={user.pid}")
            except Exception as e:
                logger.warning(f"Failed to get memory context: {e}")
        
        bot_name = get_bot_name(payload.bot_type)
        
        # âœ… æ“´å±•å°è©±æ­·å²å¾10å‰‡åˆ°20å‰‡
        messages = []
        for h in (payload.history or [])[-20:]:
            role = "assistant" if h.get("role") == "assistant" else "user"
            messages.append({"role": role, "content": h.get("content", "")})
        messages.append({"role": "user", "content": user_msg})
        
        reply_text = call_openai(system_prompt, messages)
        
        # å„²å­˜ AI å›è¦†
        ai_message = ChatMessage(
            pid=user.pid,
            bot_type=payload.bot_type,
            mode=payload.mode,
            role="ai",
            content=reply_text,
            created_at=get_tw_time(),
            meta={
                "provider": "openai",
                "model": os.getenv("OPENAI_MODEL", "gpt-4o"),
                "persona": payload.bot_type,
                "bot_name": bot_name,
                "session_id": payload.session_id,
                "memory_enabled": MEMORY_SERVICE_AVAILABLE
            }
        )
        db.add(ai_message)
        db.commit()
        db.refresh(ai_message)
        
        print(f"âœ… Chat saved: PID={user.pid}, TW={format_tw_time(ai_message.created_at)}")
        
        return SendResult(
            ok=True,
            reply=reply_text,
            bot={"type": payload.bot_type, "name": bot_name, "persona": "enhanced"},
            message_id=ai_message.id,
            session_id=payload.session_id,
            error=None
        )
        
    except Exception as e:
        db.rollback()
        print(f"âŒ Chat error: {e}")
        logger.error(f"Chat failed: {e}", exc_info=True)
        
        # è¿”å› fallback å›è¦†è€Œéç›´æ¥æ‹‹å‡ºéŒ¯èª¤
        fallback = get_fallback_reply(payload.bot_type)
        return SendResult(
            ok=False,
            reply=fallback,
            bot={"type": payload.bot_type, "name": get_bot_name(payload.bot_type), "persona": "fallback"},
            error=str(e)
        )

# ================= èŠå¤©æ­·å²èˆ‡çµ±è¨ˆ =================

@router.get("/history")
async def get_chat_history(
    limit: int = 50,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ç²å–ç•¶å‰ç”¨æˆ¶çš„èŠå¤©æ­·å²"""
    try:
        messages = (
            db.query(ChatMessage)
            .filter(ChatMessage.pid == user.pid)
            .order_by(ChatMessage.created_at.desc())
            .limit(limit)
            .all()
        )
        
        result = []
        for msg in reversed(messages):
            result.append({
                "id": msg.id,
                "pid": msg.pid,
                "role": msg.role,
                "content": msg.content,
                "bot_type": msg.bot_type,
                "mode": msg.mode,
                "created_at": msg.created_at.isoformat(),
                "meta": msg.meta or {}
            })
        
        return {
            "ok": True,
            "messages": result,
            "count": len(result)
        }
        
    except Exception as e:
        logger.error(f"Failed to fetch history: {e}")
        raise HTTPException(status_code=500, detail="Failed to fetch history")

@router.get("/stats")
async def get_chat_stats(
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ç²å–ç”¨æˆ¶çš„èŠå¤©çµ±è¨ˆè³‡è¨Š"""
    try:
        total_messages = (
            db.query(ChatMessage)
            .filter(ChatMessage.pid == user.pid)
            .count()
        )
        
        messages_by_bot = (
            db.query(
                ChatMessage.bot_type,
                func.count(ChatMessage.id).label('count')
            )
            .filter(ChatMessage.pid == user.pid)
            .group_by(ChatMessage.bot_type)
            .all()
        )
        
        first_message = (
            db.query(ChatMessage)
            .filter(ChatMessage.pid == user.pid)
            .order_by(ChatMessage.created_at.asc())
            .first()
        )
        
        last_message = (
            db.query(ChatMessage)
            .filter(ChatMessage.pid == user.pid)
            .order_by(ChatMessage.created_at.desc())
            .first()
        )
        
        return {
            "ok": True,
            "pid": user.pid,
            "stats": {
                "total_messages": total_messages,
                "messages_by_bot": {bot: count for bot, count in messages_by_bot},
                "first_message_at": first_message.created_at.isoformat() if first_message else None,
                "last_message_at": last_message.created_at.isoformat() if last_message else None
            }
        }
        
    except Exception as e:
        logger.error(f"Failed to fetch stats: {e}")
        raise HTTPException(status_code=500, detail="Failed to fetch stats")
    
@router.get("/session-history")
async def get_session_history(
    session_id: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    å–å¾—ç‰¹å®š session çš„å°è©±æ­·å²
    ç”¨æ–¼é é¢é‡æ–°è¼‰å…¥æ™‚æ¢å¾©å°è©±
    """
    try:
        print(f"ğŸ“š Loading session history: session_id={session_id}, pid={user.pid}")
        
        # æŸ¥è©¢è©² session çš„æ‰€æœ‰è¨Šæ¯
        messages = (
            db.query(ChatMessage)
            .filter(
                ChatMessage.pid == user.pid,
                ChatMessage.meta['session_id'].astext == session_id
            )
            .order_by(ChatMessage.created_at.asc())
            .all()
        )
        
        result = []
        for msg in messages:
            result.append({
                "id": msg.id,
                "role": msg.role,
                "content": msg.content,
                "bot_type": msg.bot_type,
                "timestamp": msg.created_at.isoformat(),
                "sender": "user" if msg.role == "user" else "ai"
            })
        
        print(f"âœ… Loaded {len(result)} messages for session {session_id}")
        
        return {
            "ok": True,
            "messages": result,
            "count": len(result),
            "session_id": session_id
        }
        
    except Exception as e:
        logger.error(f"Failed to fetch session history: {e}")
        return {
            "ok": False,
            "messages": [],
            "count": 0,
            "error": str(e)
        }

@router.get("/first-time-check/{bot_type}")
async def check_first_time_chat(
    bot_type: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦ç¬¬ä¸€æ¬¡èˆ‡è©²æ©Ÿå™¨äººå°è©±"""
    try:
        existing_messages = (
            db.query(ChatMessage)
            .filter(
                ChatMessage.pid == user.pid,
                ChatMessage.bot_type == bot_type
            )
            .limit(1)
            .first()
        )
        
        is_first_time = existing_messages is None
        
        return {
            "ok": True,
            "is_first_time": is_first_time,
            "bot_type": bot_type,
            "pid": user.pid
        }
        
    except Exception as e:
        logger.error(f"Failed to check first time: {e}")
        raise HTTPException(status_code=500, detail="Failed to check first time chat")