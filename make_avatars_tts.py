# make_avatars_tts.py
# 1) pip install --upgrade openai
# 2) è¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY
# 3) python make_avatars_tts.py

import os
import base64
import inspect
from pathlib import Path
from openai import OpenAI

MODEL = "gpt-4o-mini-tts"
OUTDIR = Path("tts_out")

TEXTS = {
    "Lumi_fable": "å—¨ï¼Œæˆ‘æ˜¯ Lumiã€‚æ“…é•·ä»¥æº«å’Œæå•èˆ‡æƒ…ç·’æ¨™è¨˜ï¼Œå…ˆå¹«ä½ æŠŠå¿ƒè£¡çš„æ„Ÿå—é‡æ¸…ã€‚æˆ‘å€‘æœƒä¸€èµ·è¾¨èªæ­¤åˆ»æœ€å¼·çƒˆçš„æƒ…ç·’èˆ‡éœ€æ±‚ï¼Œç·´ç¿’æŽ¥ä½è‡ªå·±ï¼Œè€Œä¸æ˜¯æ€¥è‘—è§£æ±ºã€‚è‹¥ä½ æ­£é¢è‡¨å­¤ç¨ã€å¤±è½ã€è‡ªæˆ‘æ‡·ç–‘ã€é—œä¿‚æ‹‰æ‰¯æˆ–åˆ†æ‰‹å¾©åŽŸï¼Œæˆ‘æœƒåšä½ å¯ä¾é çš„åŒè¡Œè€…ã€‚å¾žä¸€å£æ·±å‘¼å¸é–‹å§‹ï¼ŒæŠŠé€Ÿåº¦æ”¾æ…¢ï¼›æœ‰æˆ‘åœ¨ï¼Œæƒ…ç·’æ˜¯å¯ä»¥è¢«çœ‹è¦‹ã€ä¹Ÿèƒ½è¢«ç…§é¡§çš„ã€‚",
    "Solin_alloy": "ä½ å¥½ï¼Œæˆ‘æ˜¯ Solinã€‚æˆ‘æœƒå¸¶ä½ å›žæœ›ç”Ÿå‘½ç‰‡æ®µï¼Œå¾žé—œä¿‚è„ˆçµ¡èˆ‡åè¦†å‡ºç¾çš„æ¨¡å¼ï¼Œæ‰¾å‡ºæƒ…ç·’èƒŒå¾ŒçœŸæ­£çš„éœ€æ±‚ã€‚é€éŽç²¾æº–è€Œæº«æŸ”çš„å›žé¥‹ï¼Œæˆ‘å€‘æŠŠå¡ä½çš„ä½ç½®èªªæ¸…æ¥šï¼Œè®“æ”¹è®Šæœ‰æ–¹å‘ã€‚è‹¥ä½ å°è‡ªæˆ‘åƒ¹å€¼å›°æƒ‘ã€æ‰¿è¼‰å‰µå‚·è¨˜æ†¶ã€åœ¨äººéš›è£¡ä¸€å†å—å‚·ï¼Œæˆ–æƒ³ç†è§£å¤¢èˆ‡ç©ºç¼ºï¼Œæˆ‘æœƒé™ªä½ æŠŠã€Œç‚ºä»€éº¼ã€çœ‹è¦‹ã€‚ç•¶ä½ èƒ½ç†è§£è‡ªå·±ï¼Œé¸æ“‡å°±ä¸å†åªæ˜¯åæ‡‰ï¼Œè€Œæ˜¯æœ‰æ„è­˜çš„å‰è¡Œã€‚",
    "Niko_nova": "å—¨ï¼Œæˆ‘æ˜¯ Nikoã€‚å’Œæˆ‘åˆä½œæœƒå¾ˆå‹™å¯¦ï¼šå…ˆé‡æ¸…ç›®æ¨™ï¼Œå†æ‹†è§£é˜»ç¤™ï¼Œè¨­å®šå¯ä»¥å¿«é€Ÿé–‹å§‹çš„å°æ­¥è¡Œå‹•ã€‚æ¯ä¸€æ­¥éƒ½å¯è¿½è¹¤ã€å¯èª¿æ•´ã€‚é¢å°è·å ´å£“åŠ›ã€æºé€šè¡çªã€æ™‚é–“ç®¡ç†ã€æ±ºç­–å¡é—œï¼Œæˆ‘æœƒç”¨æ¸…å–®ã€å„ªå…ˆåºèˆ‡å›žé¥‹é€±æœŸå¹«ä½ å‰é€²ã€‚å…ˆå¾žæœ€å°å¯è¡Œçš„æ”¹è®Šé–‹å§‹ï¼ŒæŠŠå¯æŽ§çš„äº‹åšå¥½ï¼›ç•¶è¡Œå‹•å•Ÿå‹•ï¼Œå‹•èƒ½å°±æœƒå›žä¾†ï¼Œä½ ä¹Ÿæœƒæ›´é è¿‘æƒ³è¦çš„ç”Ÿæ´»ã€‚",
    "Clara_shimmer": "ä½ å¥½ï¼Œæˆ‘æ˜¯ Claraã€‚æˆ‘æ“…é•·ä»¥èªçŸ¥è¡Œç‚ºå–å‘ï¼Œå¹«ä½ è¾¨è­˜è‡ªå‹•æ€è€ƒèˆ‡èªçŸ¥åèª¤ï¼Œæ‰¾å‡ºè­‰æ“šï¼Œé‡å»ºæ›´è²¼è¿‘ç¾å¯¦èˆ‡åƒ¹å€¼çš„è§€é»žï¼Œä¸¦æ­é…è¡Œç‚ºå¯¦é©—èˆ‡æ—¥å¸¸ç·´ç¿’ç©©å®šæƒ…ç·’ã€‚è‹¥ä½ å¸¸é™·å…¥ç„¦æ…®ã€è² é¢è‡ªæˆ‘å°è©±ã€å®Œç¾Žä¸»ç¾©æˆ–æ‹–å»¶ï¼Œæˆ‘æœƒæä¾›æ¸…æ™°è¡¨å–®ã€é€æ­¥æŒ‡å¼•èˆ‡å›žå®¶ä½œæ¥­ã€‚ç•¶ä½ èƒ½çœ‹è¦‹å¿µé ­å¦‚ä½•å½±éŸ¿æƒ…ç·’èˆ‡è¡Œç‚ºï¼Œå°±èƒ½æŠŠè…¦ä¸­çš„çµè§£é–‹ä¾†ï¼Œé‡æ–°æ‰¾å›žæŽŒæŽ§æ„Ÿã€‚",
}

VOICE = {
    "Lumi_fable": "fable",
    "Solin_alloy": "alloy",
    "Niko_nova": "nova",
    "Clara_shimmer": "shimmer",
}

def _write_bytes(data: bytes, out_path: Path) -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    with open(out_path, "wb") as f:
        f.write(data)

def _gentle_kwargs(speech_create_func) -> dict:
    """
    è®“è²ç·šæ›´æº«æŸ”ï¼šè‹¥ SDK æ”¯æ´ï¼Œå°±å¸¶å…¥æ›´æ…¢çš„èªžé€Ÿã€‚
    - ç›®å‰å¸¸è¦‹åƒæ•¸ï¼šspeedï¼ˆæµ®é»žæ•¸ï¼Œ1.0=åŽŸé€Ÿï¼‰
    - è‹¥è©²åƒæ•¸ä¸å­˜åœ¨ï¼Œæœƒè‡ªå‹•å¿½ç•¥ä»¥ç¢ºä¿ç›¸å®¹ã€‚
    """
    sig = inspect.signature(speech_create_func)
    extra = {}
    if "speed" in sig.parameters:
        extra["speed"] = 0.92  # å¾®æ…¢ã€æ›´æŸ”å’Œ
    return extra

def synthesize(client: OpenAI, voice: str, text: str, out_path: Path) -> None:
    """
    ç›¸å®¹å„ç‰ˆæœ¬ openai-pythonï¼š
    - ä¸ç”¨ streaming
    - åµæ¸¬ 'format' æˆ– 'response_format'
    - è‹¥æ”¯æ´ 'speed'ï¼Œè‡ªå‹•å¸¶å…¥ 0.92ï¼ˆæ›´æº«æŸ”ï¼‰
    """
    create_func = client.audio.speech.create
    sig = inspect.signature(create_func)

    kwargs = {
        "model": MODEL,
        "voice": voice,
        "input": text,
        **_gentle_kwargs(create_func),
    }
    if "format" in sig.parameters:
        kwargs["format"] = "mp3"
    elif "response_format" in sig.parameters:
        kwargs["response_format"] = "mp3"

    resp = create_func(**kwargs)

    # ç›¡é‡æ¶µè“‹ä¸åŒå›žå‚³åž‹æ…‹
    if hasattr(resp, "read"):
        data = resp.read()
    elif hasattr(resp, "content"):
        data = resp.content
    elif isinstance(resp, (bytes, bytearray)):
        data = bytes(resp)
    elif isinstance(resp, dict):
        if "audio" in resp:
            data = base64.b64decode(resp["audio"])
        elif "data" in resp and isinstance(resp["data"], (bytes, bytearray)):
            data = bytes(resp["data"])
        else:
            raise RuntimeError("Unsupported response dict shape.")
    else:
        raise RuntimeError(f"Unsupported response type: {type(resp)}")

    _write_bytes(data, out_path)

def main() -> None:
    if not os.getenv("OPENAI_API_KEY"):
        raise SystemExit("ðŸ”‘ è«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY")
    client = OpenAI()
    for key, text in TEXTS.items():
        out_file = OUTDIR / f"{key}.mp3"
        synthesize(client, VOICE[key], text, out_file)
        print(f"âœ… Saved: {out_file}")

if __name__ == "__main__":
    main()
