# make_avatars_tts.py
# 1) pip install --upgrade openai python-dotenv
# 2) è¨­å®š OPENAI_API_KEY æˆ–ä½¿ç”¨ --key / --env-file åƒæ•¸
# 3) python make_avatars_tts.py [--key sk-xxxx] [--env-file .env]

import os
import re
import base64
import inspect
import argparse
from pathlib import Path
from typing import Dict
from dotenv import load_dotenv, find_dotenv
from openai import OpenAI

MODEL = "gpt-4o-mini-tts"
OUTDIR = Path("tts_out")

# === Persona è²ç·šè¨­å®š ===
# Niko/Solin ç¶­æŒåŸè¨­å®šï¼›Clara/Lumi æ”¹ç‚º novaï¼Œä¸¦å¾®èª¿ç¯€å¥èˆ‡åœé “ä»¥è²¼åˆç›®æ¨™è²æ„Ÿ
PERSONA_STYLES: Dict[str, dict] = {
    "empathy": {   # Lumiï¼ˆå¹³å’Œçš„äºæ´²å¹´è¼•å¥³æ€§ï¼‰
        "name": "Lumi",
        "voice": "nova",         # â† æ”¹ç‚º nova
        "speaking_rate": 0.93,   # æ›´æ…¢æ›´æŸ”
        "pause_factor": 1.40,    # åœé “æ›´é•·
        "energy": 0.80,          # æ›´æº«å’Œ
        "color": {"start": "#FFB6C1", "end": "#FF8FB1"},
    },
    "insight": {   # Solinï¼ˆç¶­æŒï¼‰
        "name": "Solin",
        "voice": "nova",
        "speaking_rate": 0.98,
        "pause_factor": 1.30,
        "energy": 0.77,
        "color": {"start": "#7AC2DD", "end": "#5A8CF2"},
    },
    "solution": {  # Nikoï¼ˆç¶­æŒï¼‰
        "name": "Niko",
        "voice": "nova",
        "speaking_rate": 1.00,
        "pause_factor": 1.20,
        "energy": 0.97,
        "color": {"start": "#3AA87A", "end": "#9AE6B4"},
    },
    "cognitive": { # Claraï¼ˆæ›´å¹´è¼•ã€æ¸…äº®çš„äºæ´²å¥³æ€§ï¼‰
        "name": "Clara",
        "voice": "nova",         # â† æ”¹ç‚º nova
        "speaking_rate": 1.02,   # ç¨å¿«æ›´æ¸…äº®
        "pause_factor": 1.22,    # åœé “ç•¥çŸ­
        "energy": 0.92,          # æ›´æœ‰ç²¾ç¥ä½†ä¸å°–
        "color": {"start": "#7A4DC8", "end": "#B794F4"},
    },
}

# === å½±ç‰‡é–‹å ´ç™½è…³æœ¬ï¼ˆå¯è‡ªè¡Œæ›¿æ›ï¼‰ ===
SCRIPTS: Dict[str, str] = {
    "empathy": (
        "å—¨ï¼Œæˆ‘æ˜¯ Lumiã€‚æ“…é•·ä»¥æº«å’Œæå•èˆ‡æƒ…ç·’æ¨™è¨˜ï¼Œå…ˆå¹«ä½ æŠŠå¿ƒè£¡çš„æ„Ÿå—é‡æ¸…ã€‚"
        "æˆ‘å€‘æœƒä¸€èµ·è¾¨èªæ­¤åˆ»æœ€å¼·çƒˆçš„æƒ…ç·’èˆ‡éœ€æ±‚ï¼Œç·´ç¿’æ¥ä½è‡ªå·±ï¼Œè€Œä¸æ˜¯æ€¥è‘—è§£æ±ºã€‚"
        "è‹¥ä½ æ­£é¢è‡¨å­¤ç¨ã€å¤±è½ã€è‡ªæˆ‘æ‡·ç–‘ã€é—œä¿‚æ‹‰æ‰¯æˆ–åˆ†æ‰‹å¾©åŸï¼Œæˆ‘æœƒåšä½ å¯ä¾é çš„åŒè¡Œè€…ã€‚"
        "å¾ä¸€å£æ·±å‘¼å¸é–‹å§‹ï¼ŒæŠŠé€Ÿåº¦æ”¾æ…¢ï¼›æœ‰æˆ‘åœ¨ï¼Œæƒ…ç·’æ˜¯å¯ä»¥è¢«çœ‹è¦‹ã€ä¹Ÿèƒ½è¢«ç…§é¡§çš„ã€‚"
    ),
    "insight": (
        "ä½ å¥½ï¼Œæˆ‘æ˜¯ Solinã€‚æˆ‘æœƒå¸¶ä½ å›æœ›ç”Ÿå‘½ç‰‡æ®µï¼Œå¾é—œä¿‚è„ˆçµ¡èˆ‡åè¦†å‡ºç¾çš„æ¨¡å¼ï¼Œæ‰¾å‡ºæƒ…ç·’èƒŒå¾ŒçœŸæ­£çš„éœ€æ±‚ã€‚"
        "é€éç²¾æº–è€Œæº«æŸ”çš„å›é¥‹ï¼Œæˆ‘å€‘æŠŠå¡ä½çš„ä½ç½®èªªæ¸…æ¥šï¼Œè®“æ”¹è®Šæœ‰æ–¹å‘ã€‚"
        "è‹¥ä½ å°è‡ªæˆ‘åƒ¹å€¼å›°æƒ‘ã€æ‰¿è¼‰å‰µå‚·è¨˜æ†¶ã€åœ¨äººéš›è£¡ä¸€å†å—å‚·ï¼Œæˆ–æƒ³ç†è§£å¤¢èˆ‡ç©ºç¼ºï¼Œæˆ‘æœƒé™ªä½ æŠŠã€Œç‚ºä»€éº¼ã€çœ‹è¦‹ã€‚"
        "ç•¶ä½ èƒ½ç†è§£è‡ªå·±ï¼Œé¸æ“‡å°±ä¸å†åªæ˜¯åæ‡‰ï¼Œè€Œæ˜¯æœ‰æ„è­˜çš„å‰è¡Œã€‚"
    ),
    "solution": (
        "å—¨ï¼Œæˆ‘æ˜¯ Nikoã€‚å’Œæˆ‘åˆä½œæœƒå¾ˆå‹™å¯¦ï¼šå…ˆé‡æ¸…ç›®æ¨™ï¼Œå†æ‹†è§£é˜»ç¤™ï¼Œè¨­å®šå¯ä»¥å¿«é€Ÿé–‹å§‹çš„å°æ­¥è¡Œå‹•ã€‚"
        "æ¯ä¸€æ­¥éƒ½å¯è¿½è¹¤ã€å¯èª¿æ•´ã€‚"
        "é¢å°è·å ´å£“åŠ›ã€æºé€šè¡çªã€æ™‚é–“ç®¡ç†ã€æ±ºç­–å¡é—œï¼Œæˆ‘æœƒç”¨æ¸…å–®ã€å„ªå…ˆåºèˆ‡å›é¥‹é€±æœŸå¹«ä½ å‰é€²ã€‚"
        "å…ˆå¾æœ€å°å¯è¡Œçš„æ”¹è®Šé–‹å§‹ï¼ŒæŠŠå¯æ§çš„äº‹åšå¥½ï¼›ç•¶è¡Œå‹•å•Ÿå‹•ï¼Œå‹•èƒ½å°±æœƒå›ä¾†ï¼Œä½ ä¹Ÿæœƒæ›´é è¿‘æƒ³è¦çš„ç”Ÿæ´»ã€‚"
    ),
    "cognitive": (
        "ä½ å¥½ï¼Œæˆ‘æ˜¯ Claraã€‚æˆ‘æ“…é•·ä»¥èªçŸ¥è¡Œç‚ºå–å‘ï¼Œå¹«ä½ è¾¨è­˜è‡ªå‹•æ€è€ƒèˆ‡èªçŸ¥åèª¤ï¼Œæ‰¾å‡ºè­‰æ“šï¼Œé‡å»ºæ›´è²¼è¿‘ç¾å¯¦èˆ‡åƒ¹å€¼çš„è§€é»ï¼Œ"
        "ä¸¦æ­é…è¡Œç‚ºå¯¦é©—èˆ‡æ—¥å¸¸ç·´ç¿’ç©©å®šæƒ…ç·’ã€‚"
        "è‹¥ä½ å¸¸é™·å…¥ç„¦æ…®ã€è² é¢è‡ªæˆ‘å°è©±ã€å®Œç¾ä¸»ç¾©æˆ–æ‹–å»¶ï¼Œæˆ‘æœƒæä¾›æ¸…æ™°è¡¨å–®ã€é€æ­¥æŒ‡å¼•èˆ‡å›å®¶ä½œæ¥­ã€‚"
        "ç•¶ä½ èƒ½çœ‹è¦‹å¿µé ­å¦‚ä½•å½±éŸ¿æƒ…ç·’èˆ‡è¡Œç‚ºï¼Œå°±èƒ½æŠŠè…¦ä¸­çš„çµè§£é–‹ä¾†ï¼Œé‡æ–°æ‰¾å›æŒæ§æ„Ÿã€‚"
    ),
}

# ---------- Prosody helpers ----------
PUNCS_SENTENCE = "ã€‚ï¼ï¼Ÿ"
PUNCS_CLAUSE = "ï¼Œã€ï¼›ï¼š"

def _apply_prosody(text: str, pause_factor: float, energy: float) -> str:
    # ä»¥æ¨™é»æ’å…¥ç©ºç™½/çœç•¥è™Ÿï¼Œæ¨¡æ“¬æ›´æŸ”æˆ–æ›´ä¿è½çš„åœé “ç¯€å¥
    clause_pad = 1 if pause_factor < 1.2 else (2 if pause_factor < 1.35 else 3)
    sent_pad = clause_pad + 1
    def pad_spaces(n: int) -> str: return " " * max(0, n)
    def repl_sentence(m):
        ch = m.group(0)
        suffix = "â€¦" if pause_factor >= 1.25 else ""
        return f"{ch}{suffix}{pad_spaces(sent_pad)}"
    def repl_clause(m):
        ch = m.group(0)
        suffix = "â€¦" if pause_factor >= 1.35 or energy <= 0.85 else ""
        return f"{ch}{suffix}{pad_spaces(clause_pad)}"
    text = re.sub(f"[{PUNCS_SENTENCE}]", repl_sentence, text)
    text = re.sub(f"[{PUNCS_CLAUSE}]", repl_clause, text)
    text = re.sub(r"([ã€‚ï¼ï¼Ÿ])([^ \n])", r"\1  \2", text)
    return text

# ---------- OpenAI helpers ----------
def _choose_audio_kwargs(speech_create_func, prefer_format="mp3", speed: float = None) -> dict:
    # ç›¸å®¹ä¸åŒ SDK ç‰ˆæœ¬ï¼šformat / response_format / speed
    sig = inspect.signature(speech_create_func)
    kwargs = {}
    if "format" in sig.parameters:
        kwargs["format"] = prefer_format
    elif "response_format" in sig.parameters:
        kwargs["response_format"] = prefer_format
    if speed is not None and "speed" in sig.parameters:
        kwargs["speed"] = float(speed)
    return kwargs

def _synthesize(client: OpenAI, *, model: str, voice: str, text: str, speaking_rate: float) -> bytes:
    create_func = client.audio.speech.create
    kwargs = {
        "model": model,
        "voice": voice,
        "input": text,
        **_choose_audio_kwargs(create_func, prefer_format="mp3", speed=speaking_rate),
    }
    resp = create_func(**kwargs)
    if hasattr(resp, "read"): return resp.read()
    if hasattr(resp, "content"): return resp.content
    if isinstance(resp, (bytes, bytearray)): return bytes(resp)
    if isinstance(resp, dict):
        if "audio" in resp: return base64.b64decode(resp["audio"])
        if "data" in resp and isinstance(resp["data"], (bytes, bytearray)): return bytes(resp["data"])
    raise RuntimeError(f"Unsupported response type: {type(resp)}")

def _write_bytes(data: bytes, out_path: Path) -> None:
    OUTDIR.mkdir(parents=True, exist_ok=True)
    with open(out_path, "wb") as f:
        f.write(data)

# ---------- Key loading ----------
def _load_key(args) -> None:
    # å„ªå…ˆåºï¼š--key > ç’°å¢ƒè®Šæ•¸ > --env-file/.env
    if args.key:
        os.environ["OPENAI_API_KEY"] = args.key.strip()
        return
    if args.env_file:
        load_dotenv(args.env_file, override=False)
    else:
        load_dotenv(find_dotenv(usecwd=True), override=False)

# ---------- Main ----------
def main() -> None:
    parser = argparse.ArgumentParser(description="Persona TTS generator")
    parser.add_argument("--key", help="OpenAI API Keyï¼ˆå¯é¸ï¼‰")
    parser.add_argument("--env-file", help="æŒ‡å®š .env æª”è·¯å¾‘ï¼ˆå¯é¸ï¼‰")
    args = parser.parse_args()

    _load_key(args)
    if not os.getenv("OPENAI_API_KEY"):
        raise SystemExit("ğŸ”‘ è«‹å…ˆè¨­å®š OPENAI_API_KEYï¼Œæˆ–ä½¿ç”¨ --key sk-xxxxï¼Œæˆ–æä¾› --env-file .env")

    client = OpenAI()

    for code, style in PERSONA_STYLES.items():
        name = style["name"]
        voice = style["voice"]
        rate = style["speaking_rate"]
        pause = style["pause_factor"]
        energy = style["energy"]

        raw_text = SCRIPTS[code]
        text = _apply_prosody(raw_text, pause_factor=pause, energy=energy)

        audio_bytes = _synthesize(
            client,
            model=MODEL,
            voice=voice,
            text=text,
            speaking_rate=rate,
        )

        out_path = OUTDIR / f"{name}_{voice}.mp3"
        _write_bytes(audio_bytes, out_path)
        print(f"âœ… Saved: {out_path}  (rate={rate}, pause={pause}, energy={energy})")

if __name__ == "__main__":
    main()
